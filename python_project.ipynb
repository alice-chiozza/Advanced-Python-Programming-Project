{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Parent  Child  Lengths                                          Sequences\n",
      "0       9      1     0.10  [A, G, A, T, C, A, A, G, A, T, C, A, A, G, A, ...\n",
      "1       9      2     0.40  [A, G, C, T, C, A, A, G, C, T, C, A, A, G, C, ...\n",
      "2       8      9     0.01                                                NaN\n",
      "3       8      3     0.04  [C, G, C, T, A, T, C, G, C, T, A, T, C, G, C, ...\n",
      "4       7      4     0.20  [C, G, T, T, A, C, C, G, T, T, A, C, C, G, T, ...\n",
      "5       7      5     0.08  [C, G, C, T, A, C, C, G, C, T, A, C, C, G, C, ...\n",
      "6       6      7     0.12                                                NaN\n",
      "7       6      8     0.14                                                NaN\n",
      "   Node        Vector Likelihood\n",
      "0     1  [0, 0, 0, 0]         NA\n",
      "1     2  [0, 0, 0, 0]         NA\n",
      "2     3  [0, 0, 0, 0]         NA\n",
      "3     4  [0, 0, 0, 0]         NA\n",
      "4     5  [0, 0, 0, 0]         NA\n",
      "5     6  [0, 0, 0, 0]         NA\n",
      "6     7  [0, 0, 0, 0]         NA\n",
      "7     8  [0, 0, 0, 0]         NA\n",
      "8     9  [0, 0, 0, 0]         NA\n",
      "[['A', 'G', 'A', 'T', 'C', 'A', 'A', 'G', 'A', 'T', 'C', 'A', 'A', 'G', 'A', 'T', 'C', 'A', 'A', 'G', 'A', 'T', 'C', 'A', 'A', 'G', 'A', 'T', 'C', 'A'], ['A', 'G', 'C', 'T', 'C', 'A', 'A', 'G', 'C', 'T', 'C', 'A', 'A', 'G', 'C', 'T', 'C', 'A', 'A', 'G', 'C', 'T', 'C', 'A', 'A', 'G', 'C', 'T', 'C', 'A'], ['C', 'G', 'C', 'T', 'A', 'T', 'C', 'G', 'C', 'T', 'A', 'T', 'C', 'G', 'C', 'T', 'A', 'T', 'C', 'G', 'C', 'T', 'A', 'T', 'C', 'G', 'C', 'T', 'A', 'T'], ['C', 'G', 'T', 'T', 'A', 'C', 'C', 'G', 'T', 'T', 'A', 'C', 'C', 'G', 'T', 'T', 'A', 'C', 'C', 'G', 'T', 'T', 'A', 'C', 'C', 'G', 'T', 'T', 'A', 'C'], ['C', 'G', 'C', 'T', 'A', 'C', 'C', 'G', 'C', 'T', 'A', 'C', 'C', 'G', 'C', 'T', 'A', 'C', 'C', 'G', 'C', 'T', 'A', 'C', 'C', 'G', 'C', 'T', 'A', 'C']]\n",
      "   Node        Vector Likelihood\n",
      "0     1  [1, 0, 0, 0]         NA\n",
      "1     2  [1, 0, 0, 0]         NA\n",
      "2     3  [0, 1, 0, 0]         NA\n",
      "3     4  [0, 1, 0, 0]         NA\n",
      "4     5  [0, 1, 0, 0]         NA\n",
      "5     6  [0, 0, 0, 0]         NA\n",
      "6     7  [0, 0, 0, 0]         NA\n",
      "7     8  [0, 0, 0, 0]         NA\n",
      "8     9  [0, 0, 0, 0]         NA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lou89\\AppData\\Local\\Temp\\ipykernel_29604\\605383009.py:45: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  lh_table[\"Vector\"][0] = [1,0,0,0]\n",
      "C:\\Users\\lou89\\AppData\\Local\\Temp\\ipykernel_29604\\605383009.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lh_table[\"Vector\"][0] = [1,0,0,0]\n",
      "C:\\Users\\lou89\\AppData\\Local\\Temp\\ipykernel_29604\\605383009.py:52: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  lh_table[\"Vector\"][y] = [1,0,0,0]\n",
      "C:\\Users\\lou89\\AppData\\Local\\Temp\\ipykernel_29604\\605383009.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lh_table[\"Vector\"][y] = [1,0,0,0]\n",
      "C:\\Users\\lou89\\AppData\\Local\\Temp\\ipykernel_29604\\605383009.py:52: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  lh_table[\"Vector\"][y] = [1,0,0,0]\n",
      "C:\\Users\\lou89\\AppData\\Local\\Temp\\ipykernel_29604\\605383009.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lh_table[\"Vector\"][y] = [1,0,0,0]\n",
      "C:\\Users\\lou89\\AppData\\Local\\Temp\\ipykernel_29604\\605383009.py:59: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  lh_table[\"Vector\"][y] = [0,1,0,0]\n",
      "C:\\Users\\lou89\\AppData\\Local\\Temp\\ipykernel_29604\\605383009.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lh_table[\"Vector\"][y] = [0,1,0,0]\n",
      "C:\\Users\\lou89\\AppData\\Local\\Temp\\ipykernel_29604\\605383009.py:59: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  lh_table[\"Vector\"][y] = [0,1,0,0]\n",
      "C:\\Users\\lou89\\AppData\\Local\\Temp\\ipykernel_29604\\605383009.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lh_table[\"Vector\"][y] = [0,1,0,0]\n",
      "C:\\Users\\lou89\\AppData\\Local\\Temp\\ipykernel_29604\\605383009.py:59: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  lh_table[\"Vector\"][y] = [0,1,0,0]\n",
      "C:\\Users\\lou89\\AppData\\Local\\Temp\\ipykernel_29604\\605383009.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lh_table[\"Vector\"][y] = [0,1,0,0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndef get_lh(mu, tree, seql):\\n    subtree = tree.tail(list(tree[\"Child\"]).count(\"NA\"))\\n    #print(subtree)\\n    for x in subtree[\"Sequences\"]:\\n        c = x[0]*4\\n        a = [x for x in c if c]\\n        print(a)\\n\\n    #seql = len(subtree[\"Sequences\"])\\n    #print(seql)\\n    \\n    #for x in subtree:\\n    '"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def getDF(pc, bl, seqs):\n",
    "    parent_kids = pd.read_csv(pc, delimiter =',', names = ['Parent', 'Child']) # load up the parent child table\n",
    "    branches = pd.DataFrame({\"Lengths\": list(open(bl))[0].split(',')}).astype(float) # load up the branch lengths\n",
    "    combined = pd.concat([parent_kids, branches], axis = 1) # combine parent child table + branch lengths \n",
    "\n",
    "    n = min(parent_kids.loc[:,'Parent']) # smallest parent\n",
    "    l = range(n-1,0, -1) #list of numbers from the min-1 to 1\n",
    "\n",
    "    combined = pd.concat([combined, pd.DataFrame({\"Sequences\" : [\"NA\"]*len(combined[\"Parent\"])})], axis = 1) # add NA for sequences\n",
    "\n",
    "    sequences = pd.read_csv(seqs, header = None, delimiter = \" \") # load up sequences for terminal nodes\n",
    "    #sequences = sequences.iloc[::-1] # order from highest to lowest\n",
    "    sequences.columns =[\"Child\", \"Sequence\"] # give column names\n",
    "    sequences[\"Sequence\"] = [list(x) for x in sequences[\"Sequence\"]]\n",
    "    seql = len(sequences.iloc[1,1]) # sequence length\n",
    "    \n",
    "    merged_combined = pd.merge(combined, sequences, on='Child', how='left')\n",
    "    combined['Sequences'] = merged_combined['Sequence']\n",
    "\n",
    "    # combine sequences, branch lengths for terminal nodes\n",
    "    #kids = pd.DataFrame({\"Parent\" : list(l), \"Child\" : [\"NA\"]*len(l), \"Lengths\" : [0]*len(l), \"Sequences\" : sequences[\"Lengths\"]})\n",
    "\n",
    "    # return whole combined df\n",
    "    #return pd.concat([combined, kids], ignore_index = True, axis = 0), seql\n",
    "    return combined, seql\n",
    "\n",
    "tree, seql = getDF(\"/Users/lou89/Documents/Unil/Semestre1/Python/table.dat\", \"/Users/lou89/Documents/Unil/Semestre1/Python/branchlength.dat\", \"/Users/lou89/Documents/Unil/Semestre1/Python/msa.dat\")\n",
    "print(tree)\n",
    "#print(seql)\n",
    "\n",
    "m = max(tree.loc[:,'Parent']) # biggest parent\n",
    "\n",
    "\n",
    "nts = ['A', 'C', 'G', 'T']\n",
    "\n",
    "def get_vectors(i, m, nts): #i index of nucleotide, m biggest parent, nts nucleotides sequences\n",
    "    lh_table = pd.DataFrame({\"Node\" : list(range(1,m+1,1)), \"Vector\" : m*[[0,0,0,0]], \"Likelihood\" : m*[\"NA\"]})\n",
    "    print(lh_table)\n",
    "    c = [x for x in tree[\"Sequences\"] if type(x) == list] #store sequences != NaN\n",
    "    print(c)\n",
    "    \n",
    "    lh_table[\"Vector\"][0] = [1,0,0,0]\n",
    "    #print(lh_table[\"Vector\"])\n",
    "    for y in range(len(c)):\n",
    "        #for x in range(len(nts)):\n",
    "            #print(c[y][i])\n",
    "            #print(nts[x])\n",
    "            if c[y][i] == nts[0]:\n",
    "                lh_table[\"Vector\"][y] = [1,0,0,0]\n",
    "                #lh_table[\"Vector\"][y][x] = 1\n",
    "                #lh_table.at[y, \"Vector\"][x] = 1\n",
    "                #print(lh_table[\"Vector\"][y])\n",
    "                #print(lh_table[\"Vector\"])\n",
    "                #break\n",
    "            elif c[y][i] == nts[1]:\n",
    "                 lh_table[\"Vector\"][y] = [0,1,0,0]\n",
    "            \n",
    "            elif c[y][i] == nts[2]:\n",
    "                 lh_table[\"Vector\"][y] = [0,0,1,0]\n",
    "\n",
    "            else:\n",
    "                lh_table[\"Vector\"][y] = [0,0,0,1]\n",
    "                #lh_table.at[y, \"Vector\"][x] = 0\n",
    "                #print(lh_table[\"Vector\"][y])\n",
    "                #print(lh_table[\"Vector\"])\n",
    "                #continue\n",
    "    #print(lh_table[\"Vector\"][0][1])            \n",
    "    return lh_table\n",
    "print(get_vectors(0, m, nts))\n",
    "\n",
    "'''\n",
    "def get_lh(mu, tree, seql):\n",
    "    subtree = tree.tail(list(tree[\"Child\"]).count(\"NA\"))\n",
    "    #print(subtree)\n",
    "    for x in subtree[\"Sequences\"]:\n",
    "        c = x[0]*4\n",
    "        a = [x for x in c if c]\n",
    "        print(a)\n",
    "\n",
    "    #seql = len(subtree[\"Sequences\"])\n",
    "    #print(seql)\n",
    "    \n",
    "    #for x in subtree:\n",
    "    '''\n",
    "\n",
    "#print(tree[\"Sequences\"][1][5])\n",
    "#get_lh(0.3, tree, seql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
